{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run-Length Encoding (Lossless)\n",
    "\n",
    "def rle_encode(input, dimension=1):\n",
    "\n",
    "    if dimension == 1:\n",
    "\n",
    "        if not input:\n",
    "            return ''  # Handle empty input\n",
    "\n",
    "        output = ''\n",
    "        run_length = 1\n",
    "        for i in range(1,len(input)):\n",
    "\n",
    "            if input[i] == input[i-1]:\n",
    "                run_length += 1\n",
    "            else:\n",
    "                output += str(run_length) + input[i-1]\n",
    "                run_length = 1\n",
    "\n",
    "        output += str(run_length) + input[-1]\n",
    "        return output\n",
    "\n",
    "            \n",
    "    elif dimension == 2:\n",
    "        \n",
    "        output = []\n",
    "\n",
    "        shape = input.shape\n",
    "        input = input.flatten()\n",
    "\n",
    "        run_length = 1\n",
    "\n",
    "        for i in range(1,len(input)):\n",
    "\n",
    "            if input[i] == input[i-1]:\n",
    "                run_length += 1\n",
    "            else:\n",
    "                output.append((run_length, input[i-1]))\n",
    "                run_length = 1\n",
    "\n",
    "        output.append((run_length, input[-1]))\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "def rle_decode(input, dimension=1, shape=None):\n",
    "\n",
    "    if dimension == 1:\n",
    "        decompressed = ''\n",
    "\n",
    "        i = 0\n",
    "        while i < len(input):\n",
    "            # Initialize the run_length as an empty string to accumulate digits\n",
    "            run_length = ''\n",
    "            \n",
    "            # Accumulate all the digits for the run length\n",
    "            while i < len(input) and input[i].isdigit():\n",
    "                run_length += input[i]\n",
    "                i += 1\n",
    "\n",
    "            # Convert the accumulated run length to an integer\n",
    "            run_length = int(run_length)\n",
    "            \n",
    "            # The next character is the one to repeat\n",
    "            character = input[i]\n",
    "            \n",
    "            # Append the character run_length times to the decompressed string\n",
    "            decompressed += run_length * character\n",
    "            \n",
    "            # Move to the next character\n",
    "            i += 1\n",
    "        return decompressed\n",
    "\n",
    "    elif dimension == 2:\n",
    "\n",
    "        decompressed = []\n",
    "        for run_len, val in input:\n",
    "\n",
    "            decompressed.extend(run_len*[val])\n",
    "\n",
    "        decompressed = np.array(decompressed).reshape(shape)\n",
    "        \n",
    "        return decompressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If its single dimension, we just assume a string\n",
    "\n",
    "test1 = 'AAAAABBBBCCCCCDDDDDEEEEEELLLLLPPPPBBBGGGCCCDDDWWQQQ'\n",
    "test2 = 'JJJHHHAANBVAJJJHHHPLLLLKQ'\n",
    "test3 = 'HHHHUUUUUUUUUUNNNNNNNNNBBBBBBBVVVCCCCCCCCAAAAEEEEEE'\n",
    "\n",
    "tests = [test1, test2, test3]\n",
    "\n",
    "for test in tests:    \n",
    "\n",
    "    print('Input: ', test)\n",
    "    compressed = rle_encode(test)\n",
    "\n",
    "    print('Compression: ', sys.getsizeof(compressed)/sys.getsizeof(test))\n",
    "\n",
    "    # print(compressed)\n",
    "\n",
    "    if rle_decode(compressed) == test:\n",
    "        print('SUCCESS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If its two dimenstions, we will assume an image\n",
    "test1 = np.zeros((32,32))\n",
    "test2 = np.zeros((32,32))\n",
    "test3 = np.zeros((32,32))\n",
    "\n",
    "for i in range(0,test1.shape[0], 2):\n",
    "    test1[i] = 1\n",
    "\n",
    "for i in range(0,test2.shape[1],3):\n",
    "    test2[:,i] = 1\n",
    "\n",
    "test_images = [test1, test2, test3]\n",
    "\n",
    "for img in test_images:\n",
    "    compressed = rle_encode(img,dimension=2)\n",
    "    decompressed = rle_decode(compressed, dimension=2,shape=img.shape)\n",
    "    print(sys.getsizeof(compressed)/sys.getsizeof(img))\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axes[0].imshow(img)\n",
    "    axes[1].imshow(decompressed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training AutoEncoders for compression\n",
    "# following https://www.geeksforgeeks.org/implement-deep-autoencoder-in-pytorch-for-image-reconstruction/\n",
    "import torch\n",
    "import torchvision\n",
    "plt.rcParams['figure.figsize'] = 15, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the transform for the dataset \n",
    "transform = torchvision.transforms.Compose([ \n",
    "    torchvision.transforms.ToTensor(), \n",
    "    torchvision.transforms.Normalize((0.5), (0.5)) \n",
    "])\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "# Downloading the MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST( \n",
    "    root=\"./MNIST/train\", train=True, \n",
    "    transform=torchvision.transforms.ToTensor(), \n",
    "    download=True) \n",
    "  \n",
    "test_dataset = torchvision.datasets.MNIST( \n",
    "    root=\"./MNIST/test\", train=False, \n",
    "    transform=torchvision.transforms.ToTensor(), \n",
    "    download=True) \n",
    "\n",
    "# Creating Dataloaders from the \n",
    "# training and testing dataset \n",
    "train_loader = torch.utils.data.DataLoader( \n",
    "    train_dataset, batch_size=batch_size) \n",
    "test_loader = torch.utils.data.DataLoader( \n",
    "    test_dataset, batch_size=batch_size) \n",
    "  \n",
    "# Printing 25 random images from the training dataset \n",
    "random_samples = np.random.randint( \n",
    "    1, len(train_dataset), (25)) \n",
    "  \n",
    "for idx in range(random_samples.shape[0]): \n",
    "    plt.subplot(5, 5, idx + 1) \n",
    "    plt.imshow(train_dataset[idx][0][0].numpy(), cmap='gray') \n",
    "    plt.title(train_dataset[idx][1]) \n",
    "    plt.axis('off') \n",
    "  \n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DeepAutoencoder class\n",
    "class DeepAutoencoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = torch.nn.Sequential( \n",
    "            torch.nn.Linear(28 * 28, 256), \n",
    "            torch.nn.ReLU(), \n",
    "            torch.nn.Linear(256, 128), \n",
    "            torch.nn.ReLU(), \n",
    "            torch.nn.Linear(128, 64), \n",
    "            torch.nn.ReLU(), \n",
    "            torch.nn.Linear(64, 10) \n",
    "        ) \n",
    "          \n",
    "        self.decoder = torch.nn.Sequential( \n",
    "            torch.nn.Linear(10, 64), \n",
    "            torch.nn.ReLU(), \n",
    "            torch.nn.Linear(64, 128), \n",
    "            torch.nn.ReLU(), \n",
    "            torch.nn.Linear(128, 256), \n",
    "            torch.nn.ReLU(), \n",
    "            torch.nn.Linear(256, 28 * 28), \n",
    "            torch.nn.Sigmoid() \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "    def encode(self,x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "# Instantiating the model and hyperparameters \n",
    "model = DeepAutoencoder().to(device) \n",
    "loss_fn = torch.nn.MSELoss() \n",
    "num_epochs = 50\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List that will store the training loss \n",
    "train_loss = [] \n",
    "  \n",
    "# Dictionary that will store the \n",
    "# different images and outputs for  \n",
    "# various epochs \n",
    "outputs = {}\n",
    "  \n",
    "# Training loop starts \n",
    "for epoch in range(num_epochs): \n",
    "        \n",
    "    # Initializing variable for storing  \n",
    "    # loss \n",
    "    running_loss = 0.0\n",
    "    total_batches = 0\n",
    "      \n",
    "    # Iterating over the training dataset \n",
    "    for batch in train_loader: \n",
    "            \n",
    "        # Loading image(s) and \n",
    "        # reshaping it into a 1-d vector \n",
    "        img, _ = batch\n",
    "        img = img.to(device)   \n",
    "        img = img.reshape(-1, 28*28)\n",
    "        # print(img.shape)\n",
    "        # img = img.to(device) \n",
    "          \n",
    "        # Generating output \n",
    "        out = model(img) \n",
    "          \n",
    "        # Calculating loss \n",
    "        loss = loss_fn(out, img) \n",
    "          \n",
    "        # Updating weights according \n",
    "        # to the calculated loss \n",
    "        optimizer.zero_grad() \n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "          \n",
    "        # Incrementing loss \n",
    "        running_loss += loss.item()\n",
    "        total_batches += 1 \n",
    "      \n",
    "    # Averaging out loss over entire batch \n",
    "    average_loss = running_loss / total_batches\n",
    "    train_loss.append(average_loss)\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {average_loss:.4f}\") \n",
    "      \n",
    "    # Storing useful images and \n",
    "    # reconstructed outputs for the last batch \n",
    "    outputs[epoch+1] = {'img': img.cpu().detach(), 'out': out.cpu().detach()} \n",
    "  \n",
    "  \n",
    "# Plotting the training loss \n",
    "plt.plot(range(1,num_epochs+1),train_loss) \n",
    "plt.xlabel(\"Number of epochs\") \n",
    "plt.ylabel(\"Training Loss\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting is done on a 7x5 subplot \n",
    "# Plotting the reconstructed images \n",
    "  \n",
    "# Initializing subplot counter \n",
    "counter = 1\n",
    "  \n",
    "# Plotting reconstructions \n",
    "# for epochs = [1, 5, 10, 50, 100] \n",
    "epochs_list = [1, 5, 10, 30, 50] \n",
    "  \n",
    "# Iterating over specified epochs \n",
    "for val in epochs_list: \n",
    "    \n",
    "      # Extracting recorded information \n",
    "    temp = outputs[val]['out'].detach().numpy() \n",
    "    title_text = f\"Epoch = {val}\"\n",
    "      \n",
    "    # Plotting first five images of the last batch \n",
    "    for idx in range(5): \n",
    "        plt.subplot(7, 5, counter) \n",
    "        plt.title(title_text) \n",
    "        plt.imshow(temp[idx].reshape(28,28), cmap= 'gray') \n",
    "        plt.axis('off') \n",
    "          \n",
    "        # Incrementing the subplot counter \n",
    "        counter+=1\n",
    "  \n",
    "# Plotting original images \n",
    "  \n",
    "# Iterating over first five \n",
    "# images of the last batch \n",
    "for idx in range(5): \n",
    "      \n",
    "    # Obtaining image from the dictionary \n",
    "    val = outputs[10]['img'] \n",
    "      \n",
    "    # Plotting image \n",
    "    plt.subplot(7,5,counter) \n",
    "    plt.imshow(val[idx].reshape(28, 28), \n",
    "               cmap = 'gray') \n",
    "    plt.title(\"Original Image\") \n",
    "    plt.axis('off') \n",
    "      \n",
    "    # Incrementing subplot counter \n",
    "    counter+=1\n",
    "  \n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying performance on test set\n",
    "\n",
    "# Dictionary that will store the different \n",
    "# images and outputs for various epochs \n",
    "outputs = {} \n",
    "  \n",
    "# Extracting the last batch from the test  \n",
    "# dataset \n",
    "img, _ = list(test_loader)[-1] \n",
    "  \n",
    "# Reshaping into 1d vector \n",
    "img = img.reshape(-1, 28 * 28) \n",
    "img = img.to(device)\n",
    "  \n",
    "# Generating output for the obtained \n",
    "# batch \n",
    "out = model(img) \n",
    "  \n",
    "# Storing information in dictionary \n",
    "outputs['img'] = img \n",
    "outputs['out'] = out \n",
    "  \n",
    "# Plotting reconstructed images \n",
    "# Initializing subplot counter \n",
    "counter = 1\n",
    "val = outputs['out'].cpu().detach().numpy() \n",
    "  \n",
    "# Plotting first 10 images of the batch \n",
    "for idx in range(10): \n",
    "    plt.subplot(2, 10, counter) \n",
    "    plt.title(\"Reconstructed \\n image\") \n",
    "    plt.imshow(val[idx].reshape(28, 28), cmap='gray') \n",
    "    plt.axis('off') \n",
    "  \n",
    "    # Incrementing subplot counter \n",
    "    counter += 1\n",
    "  \n",
    "# Plotting original images \n",
    "  \n",
    "# Plotting first 10 images \n",
    "for idx in range(10): \n",
    "    val = outputs['img'] \n",
    "    plt.subplot(2, 10, counter) \n",
    "    plt.imshow(val[idx].cpu().detach().reshape(28, 28), cmap='gray') \n",
    "    plt.title(\"Original Image\") \n",
    "    plt.axis('off') \n",
    "  \n",
    "    # Incrementing subplot counter \n",
    "    counter += 1\n",
    "  \n",
    "plt.tight_layout() \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the compression stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowflakes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
