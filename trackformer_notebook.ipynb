{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone and move into repo\n",
    "!git clone https://github.com/bharathsivaram10/trackformer.git\n",
    "%cd trackformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd models\n",
    "!wget https://vision.in.tum.de/webshare/u/meinhard/trackformer_models_v1.zip\n",
    "!unzip trackformer_models_v1.zip\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data zips\n",
    "%cd data\n",
    "!gdown '1-qX2d-P1Xr64ke6nTdlm33om1VxCUTSh'\n",
    "!gdown '1rqnKe9IgU_crMaxRoel9_nuUsMEBBVQu'\n",
    "!gdown '14z8Acxopj1d86-qhsF1NwS4Bv3KYa4Wu'\n",
    "!unzip VisDrone2019-MOT-train.zip\n",
    "!unzip VisDrone2019-MOT-val.zip\n",
    "!unzip VisDrone2019-MOT-test-dev.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes\n",
    "# names:\n",
    "#   0: pedestrian\n",
    "#   1: people\n",
    "#   2: bicycle\n",
    "#   3: car\n",
    "#   4: van\n",
    "#   5: truck\n",
    "#   6: tricycle\n",
    "#   7: awning-tricycle\n",
    "#   8: bus\n",
    "#   9: motor\n",
    "\n",
    "# We only want 0, 3, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "\n",
    "def visdrone2coco(data_root, custom_data_dir, subset):\n",
    "  '''\n",
    "  This function does two things:\n",
    "  - Convert the MOT annotations to COCO style expected by Trackformer\n",
    "  - Rename and change file structure such that it is the following:\n",
    "  - CustomDataDir/\n",
    "    - subset\n",
    "      - *.jpg\n",
    "    - annotations\n",
    "      - subset.json\n",
    "  '''\n",
    "\n",
    "  class_map = {0:1, 3:2, 5:3}\n",
    "\n",
    "  # Define paths\n",
    "  sequences_path = os.path.join(data_root, \"sequences\")\n",
    "  annotations_path = os.path.join(data_root, \"annotations\")\n",
    "  output_annotations_file = os.path.join(custom_data_dir, \"annotations\", f\"{subset}.json\")\n",
    "\n",
    "  # Prepare COCO structure\n",
    "  coco_data = {\n",
    "      \"images\": [],\n",
    "      \"annotations\": [],\n",
    "      \"categories\": [{\"id\": 1, \"name\": \"person\"}, {\"id\": 2, \"name\": \"car\"}, {\"id\": 3, \"name\": \"truck\"}]\n",
    "  }\n",
    "  image_id = 1\n",
    "  annotation_id = 1\n",
    "  seq_info = {}\n",
    "\n",
    "  # Process each sequence\n",
    "  for seq_name in sorted(os.listdir(sequences_path)):\n",
    "      seq_folder = os.path.join(sequences_path, seq_name)\n",
    "      annotation_file = os.path.join(annotations_path, f\"{seq_name}.txt\")\n",
    "\n",
    "      if not os.path.isdir(seq_folder) or not os.path.exists(annotation_file):\n",
    "        continue\n",
    "\n",
    "      # Get all images and sort by frame number\n",
    "      images = sorted(os.listdir(seq_folder))\n",
    "      seq_length = len(images)\n",
    "      first_frame_image_id = image_id\n",
    "\n",
    "      # Move and rename images\n",
    "      frame_map = {}\n",
    "      for img in images:\n",
    "          frame_num = int(os.path.splitext(img)[0])\n",
    "          new_filename = f\"{seq_name}_{frame_num}.jpg\"\n",
    "          shutil.move(os.path.join(seq_folder, img), os.path.join(custom_data_dir, subset, new_filename))\n",
    "\n",
    "          # Register image in COCO\n",
    "          frame_map[frame_num] = image_id\n",
    "          coco_data[\"images\"].append({\n",
    "              \"id\": image_id,\n",
    "              \"file_name\": new_filename,\n",
    "              \"seq_name\": seq_name,\n",
    "              \"frame_id\": frame_num,\n",
    "              \"seq_length\": seq_length,\n",
    "              \"first_frame_image_id\": first_frame_image_id\n",
    "          })\n",
    "          image_id += 1\n",
    "\n",
    "      # Process annotations\n",
    "      with open(annotation_file, \"r\") as f:\n",
    "          for line in f:\n",
    "              frame_id, track_id, x, y, w, h, not_ignored, class_id, _, _ = map(float, line.strip().split(\",\"))\n",
    "\n",
    "              if not not_ignored or int(class_id) not in class_map:\n",
    "                  continue\n",
    "\n",
    "              frame_id = int(frame_id)\n",
    "              if frame_id not in frame_map:\n",
    "                  continue  # Skip if frame_id does not exist in the image mapping\n",
    "\n",
    "              coco_data[\"annotations\"].append({\n",
    "                  \"id\": annotation_id,\n",
    "                  \"bbox\": [x, y, w, h],\n",
    "                  \"image_id\": frame_map[frame_id],\n",
    "                  \"segmentation\" : [],\n",
    "                  \"ignore\": 0,\n",
    "                  \"visibility\" : 0.5,\n",
    "                  \"area\" : w * h,\n",
    "                  \"iscrowd\" : 0,\n",
    "                  \"seq\": seq_name,\n",
    "                  \"category_id\": class_map[int(class_id)],\n",
    "                  \"track_id\": int(track_id),\n",
    "              })\n",
    "              annotation_id += 1\n",
    "\n",
    "\n",
    "  # Save COCO annotations\n",
    "  with open(output_annotations_file, \"w\") as f:\n",
    "      json.dump(coco_data, f, indent=4)\n",
    "\n",
    "  print(\"Dataset restructuring and annotation conversion completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visdrone2coco('VisDrone2019-MOT-train', 'VisDrone', 'train')\n",
    "visdrone2coco('VisDrone2019-MOT-val', 'VisDrone', 'val')\n",
    "visdrone2coco('VisDrone2019-MOT-test-dev', 'VisDrone', 'test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/trackformer/models/ops/setup.py build --build-base=src/trackformer/models/ops/ install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sacred visdom motmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Training\n",
    "!python src/train.py with \\\n",
    "    mot17 \\\n",
    "    deformable \\\n",
    "    multi_frame \\\n",
    "    tracking \\\n",
    "    resume=models/mot17_crowdhuman_deformable_multi_frame/checkpoint_epoch_40.pth \\\n",
    "    output_dir=models/VisDrone_deformable \\\n",
    "    mot_path_train=data/VisDrone \\\n",
    "    mot_path_val=data/VisDrone \\\n",
    "    train_split=train \\\n",
    "    val_split=val \\\n",
    "    epochs=20"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
